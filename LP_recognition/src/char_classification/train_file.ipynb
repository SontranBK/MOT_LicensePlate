{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "gmRlqcvMQUDJ",
        "outputId": "07c1fe81-717a-4b97-ace1-d2fc23004909"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.13 ('TEST')' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n TEST ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "jagkCNPOQKNR",
        "outputId": "464a0511-851a-4607-bccd-048d2d5ae7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/LP_Recognition\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My\\ Drive/LP_Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "colab_type": "code",
        "id": "NS_5W_vEQqdN",
        "outputId": "0369a713-a73e-4768-c6c2-03779578cc52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 5, 5, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                16416     \n",
            "=================================================================\n",
            "Total params: 188,544\n",
            "Trainable params: 188,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "-------------DONE------------\n",
            "The number of train digits data:  13732\n",
            "-------------DONE------------\n",
            "The number of train alphas data:  1983\n"
          ]
        }
      ],
      "source": [
        "from model import CNN_Model\n",
        "\n",
        "model = CNN_Model(trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "RyOFTwBrRCRU",
        "outputId": "44a04989-c8a8-4832-f927-17ef4b59e9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training......\n",
            "Epoch 1/30\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 2.1688 - acc: 0.3850 - val_loss: 0.4376 - val_acc: 0.8680 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.5847 - acc: 0.8094 - val_loss: 0.1241 - val_acc: 0.9577 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 1s 8ms/step - loss: 0.3292 - acc: 0.8942 - val_loss: 0.0981 - val_acc: 0.9723 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.2497 - acc: 0.9233 - val_loss: 0.0816 - val_acc: 0.9761 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.1891 - acc: 0.9412 - val_loss: 0.0751 - val_acc: 0.9773 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.1592 - acc: 0.9507 - val_loss: 0.0652 - val_acc: 0.9773 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.1437 - acc: 0.9558 - val_loss: 0.0682 - val_acc: 0.9809 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.1238 - acc: 0.9626 - val_loss: 0.0678 - val_acc: 0.9813 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.1095 - acc: 0.9653 - val_loss: 0.0596 - val_acc: 0.9836 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.0999 - acc: 0.9705 - val_loss: 0.0605 - val_acc: 0.9842 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.1006 - acc: 0.9699 - val_loss: 0.0512 - val_acc: 0.9842 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0860 - acc: 0.9755 - val_loss: 0.0589 - val_acc: 0.9824 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0762 - acc: 0.9771 - val_loss: 0.0555 - val_acc: 0.9836 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 2s 8ms/step - loss: 0.0774 - acc: 0.9772 - val_loss: 0.0502 - val_acc: 0.9883 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0705 - acc: 0.9795 - val_loss: 0.0495 - val_acc: 0.9881 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0660 - acc: 0.9817 - val_loss: 0.0555 - val_acc: 0.9863 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0699 - acc: 0.9793 - val_loss: 0.0491 - val_acc: 0.9876 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0622 - acc: 0.9817 - val_loss: 0.0541 - val_acc: 0.9845 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0672 - acc: 0.9814 - val_loss: 0.0450 - val_acc: 0.9885 - lr: 0.0010\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0638 - acc: 0.9818 - val_loss: 0.0464 - val_acc: 0.9885 - lr: 0.0010\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 1s 8ms/step - loss: 0.0556 - acc: 0.9850 - val_loss: 0.0422 - val_acc: 0.9908 - lr: 0.0010\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0523 - acc: 0.9853 - val_loss: 0.0447 - val_acc: 0.9899 - lr: 0.0010\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0502 - acc: 0.9863 - val_loss: 0.0495 - val_acc: 0.9876 - lr: 0.0010\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0533 - acc: 0.9845 - val_loss: 0.0572 - val_acc: 0.9896 - lr: 0.0010\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0463 - acc: 0.9864 - val_loss: 0.0491 - val_acc: 0.9901 - lr: 0.0010\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9874\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0456 - acc: 0.9874 - val_loss: 0.0522 - val_acc: 0.9899 - lr: 0.0010\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 1s 8ms/step - loss: 0.0348 - acc: 0.9909 - val_loss: 0.0439 - val_acc: 0.9908 - lr: 2.0000e-04\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0302 - acc: 0.9921 - val_loss: 0.0416 - val_acc: 0.9908 - lr: 2.0000e-04\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0254 - acc: 0.9927 - val_loss: 0.0422 - val_acc: 0.9912 - lr: 2.0000e-04\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 1s 7ms/step - loss: 0.0248 - acc: 0.9930 - val_loss: 0.0435 - val_acc: 0.9899 - lr: 2.0000e-04\n"
          ]
        }
      ],
      "source": [
        "model.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LP_Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('TEST')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "6e2fee2a68bdf846499c400e5420c90a5c2b6bc5520d1f94632eb8db131cdab3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
